{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Linear and Logistic Regression\n",
    "\n",
    "**Introduction to Machine Learning and Deep Learning** – ELTE Faculty of Informatics, 2024/25 Spring Semester\n",
    "\n",
    "This notebook demonstrates the material from `prez2a.pdf` (Linear Regression) and `prez2b.pdf` (Logistic Regression, Classification) with code and visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "**Contents:**\n",
    "1. [Linear Regression](#1-linear-regression)\n",
    "   - 1.1 Simple linear regression from scratch\n",
    "   - 1.2 Multiple linear regression\n",
    "   - 1.3 Polynomial regression\n",
    "   - 1.4 Regularization (Ridge, Lasso, Elastic Net)\n",
    "   - 1.5 Learning curves\n",
    "2. [Logistic Regression and Classification](#2-logistic-regression-and-classification)\n",
    "   - 2.1 Binary logistic regression\n",
    "   - 2.2 Evaluation metrics\n",
    "   - 2.3 ROC and Precision-Recall curves\n",
    "   - 2.4 Multi-class classification\n",
    "   - 2.5 Imbalanced datasets\n",
    "3. [Exercises](#3-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score,\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, auc, precision_recall_curve, RocCurveDisplay, log_loss\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "print('Imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Linear Regression\n",
    "\n",
    "The goal of linear regression: predict a continuous target variable ($y$) as a linear combination of input features ($X$).\n",
    "\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_n x_n = \\mathbf{\\theta}^T \\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Simple Linear Regression from Scratch\n",
    "\n",
    "First, we demonstrate the method on synthetic data with a manual implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# y = 3 + 2*x + noise\n",
    "X_simple = 2 * np.random.rand(100, 1)\n",
    "y_simple = 3 + 2 * X_simple + np.random.randn(100, 1) * 0.5\n",
    "\n",
    "plt.scatter(X_simple, y_simple, alpha=0.6, edgecolors='k', s=40)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Synthetic data: y = 3 + 2x + noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE Cost Function\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta^T x^{(i)} - y^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    \"\"\"MSE cost function.\"\"\"\n",
    "    m = len(y)\n",
    "    predictions = X @ theta\n",
    "    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "# Add bias column (x0 = 1)\n",
    "X_b = np.c_[np.ones((100, 1)), X_simple]\n",
    "\n",
    "# Test with random theta\n",
    "theta_init = np.random.randn(2, 1)\n",
    "print(f'Initial theta: {theta_init.ravel()}')\n",
    "print(f'Initial cost: {compute_cost(X_b, y_simple, theta_init):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent\n",
    "\n",
    "The gradient:\n",
    "$$\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)}$$\n",
    "\n",
    "Update rule:\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def batch_gradient_descent(X, y, theta, learning_rate, n_iterations):\n",
    "    \"\"\"Batch gradient descent with cost history.\"\"\"\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "    theta_history = [theta.copy()]\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        gradients = (1 / m) * X.T @ (X @ theta - y)\n",
    "        theta = theta - learning_rate * gradients\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "        theta_history.append(theta.copy())\n",
    "\n",
    "    return theta, cost_history, theta_history\n",
    "\n",
    "# Run gradient descent\n",
    "learning_rate = 0.1\n",
    "n_iterations = 100\n",
    "theta_init = np.random.randn(2, 1)\n",
    "\n",
    "theta_gd, cost_history, theta_history = batch_gradient_descent(\n",
    "    X_b, y_simple, theta_init, learning_rate, n_iterations\n",
    ")\n",
    "\n",
    "print(f'Gradient Descent result: theta0 = {theta_gd[0,0]:.4f}, theta1 = {theta_gd[1,0]:.4f}')\n",
    "print(f'(True values: theta0 = 3, theta1 = 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Visualize cost convergence\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cost over iterations\n",
    "axes[0].plot(cost_history, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('Cost (MSE/2)')\n",
    "axes[0].set_title('Cost Function Convergence')\n",
    "\n",
    "# Regression line at different iterations\n",
    "axes[1].scatter(X_simple, y_simple, alpha=0.5, s=30, label='Data points')\n",
    "X_plot = np.array([[0], [2]])\n",
    "X_plot_b = np.c_[np.ones((2, 1)), X_plot]\n",
    "\n",
    "for step in [0, 1, 2, 5, 10, n_iterations]:\n",
    "    theta_step = theta_history[min(step, len(theta_history)-1)]\n",
    "    y_plot = X_plot_b @ theta_step\n",
    "    style = 'r-' if step == n_iterations else '--'\n",
    "    alpha = 1.0 if step == n_iterations else 0.4\n",
    "    axes[1].plot(X_plot, y_plot, style, alpha=alpha, label=f'Iteration {step}')\n",
    "\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('y')\n",
    "axes[1].set_title('Regression Line Evolution')\n",
    "axes[1].legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Learning Rate ($\\alpha$)\n",
    "\n",
    "Too small: slow convergence. Too large: may diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "titles = ['Too small (\\u03b1=0.01)', 'Appropriate (\\u03b1=0.1)', 'Large (\\u03b1=0.5)']\n",
    "\n",
    "for ax, lr, title in zip(axes, learning_rates, titles):\n",
    "    theta_init = np.random.RandomState(42).randn(2, 1)\n",
    "    _, costs, _ = batch_gradient_descent(X_b, y_simple, theta_init, lr, 50)\n",
    "    ax.plot(costs, linewidth=2)\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Cost')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, max(costs[0] * 1.1, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "SGD uses only **one** random sample per iteration to estimate the gradient. Faster but noisier convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def stochastic_gradient_descent(X, y, theta, learning_rate, n_epochs):\n",
    "    \"\"\"Stochastic gradient descent.\"\"\"\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        indices = np.random.permutation(m)\n",
    "        for i in indices:\n",
    "            xi = X[i:i+1]\n",
    "            yi = y[i:i+1]\n",
    "            gradient = xi.T @ (xi @ theta - yi)\n",
    "            theta = theta - learning_rate * gradient\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "theta_init = np.random.RandomState(42).randn(2, 1)\n",
    "theta_sgd, cost_sgd = stochastic_gradient_descent(X_b, y_simple, theta_init, 0.01, 50)\n",
    "\n",
    "# Compare BGD vs SGD\n",
    "theta_init = np.random.RandomState(42).randn(2, 1)\n",
    "_, cost_bgd, _ = batch_gradient_descent(X_b, y_simple, theta_init, 0.1, 50)\n",
    "\n",
    "plt.plot(cost_bgd, label='Batch GD', linewidth=2)\n",
    "plt.plot(cost_sgd, label='Stochastic GD', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Batch GD vs. Stochastic GD')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'SGD result: theta0 = {theta_sgd[0,0]:.4f}, theta1 = {theta_sgd[1,0]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation\n",
    "\n",
    "Closed-form solution, no iteration required:\n",
    "\n",
    "$$\\hat{\\theta} = (X^T X)^{-1} X^T y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def normal_equation(X, y):\n",
    "    \"\"\"Closed-form solution for linear regression.\"\"\"\n",
    "    return np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "theta_ne = normal_equation(X_b, y_simple)\n",
    "print(f'Normal equation: theta0 = {theta_ne[0,0]:.4f}, theta1 = {theta_ne[1,0]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_simple, y_simple)\n",
    "\n",
    "print(f'sklearn:      intercept = {lin_reg.intercept_[0]:.4f}, coef = {lin_reg.coef_[0][0]:.4f}')\n",
    "print(f'Normal eq:    theta0 = {theta_ne[0,0]:.4f}, theta1 = {theta_ne[1,0]:.4f}')\n",
    "print(f'Grad. desc:   theta0 = {theta_gd[0,0]:.4f}, theta1 = {theta_gd[1,0]:.4f}')\n",
    "print('\\nAll three methods produce nearly identical results!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Multiple Linear Regression\n",
    "\n",
    "Demonstrated on real data: **USA Housing** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_housing = pd.read_csv('data/USA_Housing.csv')\n",
    "print(f'Dataset shape: {df_housing.shape}')\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Feature matrix and target\n",
    "feature_cols = ['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
    "                'Avg. Area Number of Bedrooms', 'Area Population']\n",
    "X_housing = df_housing[feature_cols]\n",
    "y_housing = df_housing['Price']\n",
    "\n",
    "# Train-test split\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "**Standardization** (Z-score): $x' = \\frac{x - \\mu}{\\sigma}$ → mean=0, std=1\n",
    "\n",
    "**Normalization** (Min-Max): $x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$ → [0, 1] range\n",
    "\n",
    "Important: the scaler must be **fit only on the training data**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_h_scaled = scaler.fit_transform(X_train_h)\n",
    "X_test_h_scaled = scaler.transform(X_test_h)\n",
    "\n",
    "# Show the effect of scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].boxplot(X_train_h.values, labels=[c[:10] for c in feature_cols])\n",
    "axes[0].set_title('Before Scaling')\n",
    "axes[0].tick_params(axis='x', rotation=30)\n",
    "\n",
    "axes[1].boxplot(X_train_h_scaled, labels=[c[:10] for c in feature_cols])\n",
    "axes[1].set_title('After Standardization')\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit linear regression\n",
    "lr_housing = LinearRegression()\n",
    "lr_housing.fit(X_train_h_scaled, y_train_h)\n",
    "\n",
    "y_pred_h = lr_housing.predict(X_test_h_scaled)\n",
    "\n",
    "print(f'MSE:  {mean_squared_error(y_test_h, y_pred_h):,.2f}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test_h, y_pred_h)):,.2f}')\n",
    "print(f'R\\u00b2:   {r2_score(y_test_h, y_pred_h):.4f}')\n",
    "\n",
    "# Coefficients\n",
    "coef_df = pd.DataFrame({'Feature': feature_cols, 'Coefficient': lr_housing.coef_})\n",
    "coef_df = coef_df.sort_values('Coefficient', ascending=True)\n",
    "print(f'\\nIntercept: {lr_housing.intercept_:,.2f}')\n",
    "print('\\nCoefficients:')\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Residual analysis\n",
    "residuals = y_test_h - y_pred_h\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Predicted vs actual\n",
    "axes[0].scatter(y_test_h, y_pred_h, alpha=0.3, s=10)\n",
    "axes[0].plot([y_test_h.min(), y_test_h.max()], [y_test_h.min(), y_test_h.max()], 'r--', linewidth=2)\n",
    "axes[0].set_xlabel('Actual Price')\n",
    "axes[0].set_ylabel('Predicted Price')\n",
    "axes[0].set_title('Prediction vs. Actual')\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Residuals')\n",
    "axes[1].set_title('Residual Distribution')\n",
    "\n",
    "# Residuals vs predicted\n",
    "axes[2].scatter(y_pred_h, residuals, alpha=0.3, s=10)\n",
    "axes[2].axhline(y=0, color='r', linestyle='--')\n",
    "axes[2].set_xlabel('Predicted Price')\n",
    "axes[2].set_ylabel('Residuals')\n",
    "axes[2].set_title('Residuals vs. Prediction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Polynomial Regression\n",
    "\n",
    "We can model nonlinear relationships with linear regression by expanding the features using polynomial transformation.\n",
    "\n",
    "E.g. degree 2: $\\hat{y} = \\theta_0 + \\theta_1 x + \\theta_2 x^2$\n",
    "\n",
    "**Warning:** high degree polynomials can lead to overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate nonlinear data\n",
    "np.random.seed(RANDOM_STATE)\n",
    "X_poly = np.sort(6 * np.random.rand(80, 1) - 3, axis=0)\n",
    "y_poly = 0.5 * X_poly**3 - X_poly**2 + 2 + np.random.randn(80, 1) * 3\n",
    "\n",
    "plt.scatter(X_poly, y_poly, alpha=0.6, edgecolors='k', s=40)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Nonlinear Synthetic Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare different polynomial degrees\n",
    "degrees = [1, 3, 10, 20]\n",
    "X_plot_poly = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "titles = ['Underfitting (degree=1)', 'Good fit (degree=3)', 'Beginning to overfit (degree=10)', 'Overfitting (degree=20)']\n",
    "\n",
    "for ax, degree, title in zip(axes.ravel(), degrees, titles):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly_feat = poly.fit_transform(X_poly)\n",
    "    X_plot_feat = poly.transform(X_plot_poly)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_poly_feat, y_poly)\n",
    "    y_plot = lr.predict(X_plot_feat)\n",
    "\n",
    "    train_mse = mean_squared_error(y_poly, lr.predict(X_poly_feat))\n",
    "\n",
    "    ax.scatter(X_poly, y_poly, alpha=0.5, s=30)\n",
    "    ax.plot(X_plot_poly, y_plot, 'r-', linewidth=2)\n",
    "    ax.set_title(f'{title}\\nTrain MSE: {train_mse:.2f}')\n",
    "    ax.set_ylim(y_poly.min() - 10, y_poly.max() + 10)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff\n",
    "\n",
    "- **Underfitting (high bias):** The model is too simple, unable to capture the patterns in the data.\n",
    "- **Overfitting (high variance):** The model is too complex, it learns the noise too.\n",
    "- **Goal:** find the right complexity (\"sweet spot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train vs test error for different polynomial degrees\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
    "    X_poly, y_poly, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "degrees_range = range(1, 16)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for d in degrees_range:\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_tr = poly.fit_transform(X_train_p)\n",
    "    X_te = poly.transform(X_test_p)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_tr, y_train_p)\n",
    "\n",
    "    train_errors.append(mean_squared_error(y_train_p, lr.predict(X_tr)))\n",
    "    test_errors.append(mean_squared_error(y_test_p, lr.predict(X_te)))\n",
    "\n",
    "plt.plot(list(degrees_range), train_errors, 'b-o', label='Train MSE')\n",
    "plt.plot(list(degrees_range), test_errors, 'r-o', label='Test MSE')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Bias-Variance Tradeoff: Train vs. Test Error')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Regularization\n",
    "\n",
    "Regularization protects against overfitting by adding a penalty term to the cost function.\n",
    "\n",
    "| Method | Penalty Term | Effect |\n",
    "|--------|-------------|--------|\n",
    "| **Ridge (L2)** | $\\alpha \\sum \\theta_j^2$ | Shrinks coefficients toward zero |\n",
    "| **Lasso (L1)** | $\\alpha \\sum |\\theta_j|$ | Can push coefficients exactly to zero (feature selection) |\n",
    "| **Elastic Net** | $\\alpha (r \\sum |\\theta_j| + \\frac{1-r}{2} \\sum \\theta_j^2)$ | Combination of L1 and L2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Demonstrate regularization on high-degree polynomial\n",
    "degree = 10\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_poly_reg = poly.fit_transform(X_poly)\n",
    "X_plot_reg = poly.transform(X_plot_poly)\n",
    "\n",
    "# Scale features for regularization\n",
    "scaler_poly = StandardScaler()\n",
    "X_poly_reg_s = scaler_poly.fit_transform(X_poly_reg)\n",
    "X_plot_reg_s = scaler_poly.transform(X_plot_reg)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "models = [\n",
    "    ('Ridge (L2)', Ridge(alpha=1.0)),\n",
    "    ('Lasso (L1)', Lasso(alpha=0.1)),\n",
    "    ('Elastic Net', ElasticNet(alpha=0.1, l1_ratio=0.5))\n",
    "]\n",
    "\n",
    "for ax, (name, model) in zip(axes, models):\n",
    "    model.fit(X_poly_reg_s, y_poly.ravel())\n",
    "    y_plot = model.predict(X_plot_reg_s)\n",
    "\n",
    "    ax.scatter(X_poly, y_poly, alpha=0.5, s=30)\n",
    "    ax.plot(X_plot_poly, y_plot, 'r-', linewidth=2)\n",
    "    ax.set_title(f'{name}\\nNon-zero coefficients: {np.sum(np.abs(model.coef_) > 1e-6)}/{len(model.coef_)}')\n",
    "    ax.set_ylim(y_poly.min() - 10, y_poly.max() + 10)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Alpha effect on Ridge coefficients\n",
    "alphas = np.logspace(-2, 4, 100)\n",
    "coefs_ridge = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    ridge.fit(X_poly_reg_s, y_poly.ravel())\n",
    "    coefs_ridge.append(ridge.coef_)\n",
    "\n",
    "coefs_ridge = np.array(coefs_ridge)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(coefs_ridge.shape[1]):\n",
    "    plt.plot(alphas, coefs_ridge[:, i], linewidth=1)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (regularization parameter)')\n",
    "plt.ylabel('Coefficient value')\n",
    "plt.title('Ridge: Coefficient paths as a function of alpha')\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Learning Curves\n",
    "\n",
    "The learning curve shows how the training and validation error change as the amount of training data increases.\n",
    "\n",
    "- **High bias:** both curves converge at a high error level (→ need a more complex model)\n",
    "- **High variance:** large gap between training and validation error (→ need more data or regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_learning_curve(estimator, X, y, title, ax):\n",
    "    \"\"\"Plot learning curve for a given estimator.\"\"\"\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator, X, y, cv=5,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    train_mean = -train_scores.mean(axis=1)\n",
    "    train_std = train_scores.std(axis=1)\n",
    "    val_mean = -val_scores.mean(axis=1)\n",
    "    val_std = val_scores.std(axis=1)\n",
    "\n",
    "    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "    ax.plot(train_sizes, train_mean, 'b-o', label='Train', markersize=4)\n",
    "    ax.plot(train_sizes, val_mean, 'r-o', label='Validation', markersize=4)\n",
    "    ax.set_xlabel('Number of Training Samples')\n",
    "    ax.set_ylabel('MSE')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Underfitting model\n",
    "pipe_linear = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=1)),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "plot_learning_curve(pipe_linear, X_poly, y_poly.ravel(), 'Linear (high bias)', axes[0])\n",
    "\n",
    "# Good model\n",
    "pipe_cubic = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "plot_learning_curve(pipe_cubic, X_poly, y_poly.ravel(), 'Cubic (good fit)', axes[1])\n",
    "\n",
    "# Overfitting model\n",
    "pipe_high = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=15)),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "plot_learning_curve(pipe_high, X_poly, y_poly.ravel(), 'Degree 15 (high variance)', axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Logistic Regression and Classification\n",
    "\n",
    "Logistic regression is used for **classification** tasks. The output is a probability (between $0$ and $1$), ensured by the **sigmoid** function:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad \\text{where } z = \\theta^T x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-7, 7, 200)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(z, sigmoid(z), 'b-', linewidth=2.5)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Threshold = 0.5')\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axhline(y=1, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('z = \\u03b8\\u1d40x')\n",
    "plt.ylabel('\\u03c3(z)')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.legend()\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate 2D classification data\n",
    "np.random.seed(RANDOM_STATE)\n",
    "X_cls, y_cls = make_classification(\n",
    "    n_samples=200, n_features=2, n_redundant=0, n_informative=2,\n",
    "    n_clusters_per_class=1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Fit logistic regression\n",
    "log_reg = LogisticRegression(random_state=RANDOM_STATE)\n",
    "log_reg.fit(X_cls, y_cls)\n",
    "\n",
    "# Plot decision boundary\n",
    "def plot_decision_boundary(model, X, y, ax=None, title=''):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolors='k', s=40, label='Class 0')\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], c='red', edgecolors='k', s=40, label='Class 1')\n",
    "    ax.set_xlabel('x\\u2081')\n",
    "    ax.set_ylabel('x\\u2082')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "plot_decision_boundary(log_reg, X_cls, y_cls, title='Logistic Regression Decision Boundary')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {log_reg.score(X_cls, y_cls):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function (Cross-Entropy / Log-Loss)\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{p}^{(i)}) + (1-y^{(i)}) \\log(1 - \\hat{p}^{(i)}) \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Visualize log-loss for a single sample\n",
    "p = np.linspace(0.001, 0.999, 200)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# When y = 1\n",
    "axes[0].plot(p, -np.log(p), 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted probability p')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Cost when y = 1: -log(p)')\n",
    "\n",
    "# When y = 0\n",
    "axes[1].plot(p, -np.log(1 - p), 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted probability p')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Cost when y = 0: -log(1-p)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('If the prediction is correct (p close to y) -> low cost')\n",
    "print('If the prediction is wrong (p far from y)  -> very high cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Evaluation Metrics\n",
    "\n",
    "Demonstrated on real data: **Heart Disease** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_heart = pd.read_csv('data/heart-disease.csv')\n",
    "print(f'Dataset shape: {df_heart.shape}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(df_heart['target'].value_counts())\n",
    "df_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_heart = df_heart.drop('target', axis=1)\n",
    "y_heart = df_heart['target']\n",
    "\n",
    "X_train_heart, X_test_heart, y_train_heart, y_test_heart = train_test_split(\n",
    "    X_heart, y_heart, test_size=0.2, random_state=RANDOM_STATE, stratify=y_heart\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_heart = StandardScaler()\n",
    "X_train_heart_s = scaler_heart.fit_transform(X_train_heart)\n",
    "X_test_heart_s = scaler_heart.transform(X_test_heart)\n",
    "\n",
    "# Fit logistic regression\n",
    "log_reg_heart = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "log_reg_heart.fit(X_train_heart_s, y_train_heart)\n",
    "\n",
    "y_pred_heart = log_reg_heart.predict(X_test_heart_s)\n",
    "y_prob_heart = log_reg_heart.predict_proba(X_test_heart_s)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "|  | Predicted: Positive | Predicted: Negative |\n",
    "|---|---|---|\n",
    "| **Actual: Positive** | TP (True Positive) | FN (False Negative) |\n",
    "| **Actual: Negative** | FP (False Positive) | TN (True Negative) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_heart, y_pred_heart)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No disease (0)', 'Disease (1)'],\n",
    "            yticklabels=['No disease (0)', 'Disease (1)'])\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F1-score\n",
    "\n",
    "- **Precision**: $\\frac{TP}{TP + FP}$ – Of all predicted positives, how many are truly positive?\n",
    "- **Recall** (Sensitivity): $\\frac{TP}{TP + FN}$ – Of all actual positives, how many did we find?\n",
    "- **F1-score**: $2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$ – Harmonic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print('=' * 55)\n",
    "print(classification_report(y_test_heart, y_pred_heart,\n",
    "                            target_names=['No disease', 'Disease']))\n",
    "\n",
    "print(f'Accuracy:          {accuracy_score(y_test_heart, y_pred_heart):.4f}')\n",
    "print(f'Balanced accuracy: {balanced_accuracy_score(y_test_heart, y_pred_heart):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve (Receiver Operating Characteristic)\n",
    "\n",
    "The ROC curve shows the relationship between **True Positive Rate** (Recall) and **False Positive Rate** at different thresholds.\n",
    "\n",
    "- **AUC = 1.0**: perfect classifier\n",
    "- **AUC = 0.5**: random (diagonal line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds_roc = roc_curve(y_test_heart, y_prob_heart)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC curve\n",
    "axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', alpha=0.5, label='Random')\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate (Recall)')\n",
    "axes[0].set_title('ROC Curve')\n",
    "axes[0].legend()\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test_heart, y_prob_heart)\n",
    "axes[1].plot(recall_curve, precision_curve, 'g-', linewidth=2)\n",
    "axes[1].fill_between(recall_curve, precision_curve, alpha=0.1, color='green')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Tuning\n",
    "\n",
    "The default threshold is 0.5, but in medical diagnostics a high recall (few FN) may be more important, while in spam filtering a high precision (few FP) is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.1, 0.95, 0.05)\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob_heart >= t).astype(int)\n",
    "    results.append({\n",
    "        'Threshold': t,\n",
    "        'Precision': precision_score(y_test_heart, y_pred_t, zero_division=0),\n",
    "        'Recall': recall_score(y_test_heart, y_pred_t, zero_division=0),\n",
    "        'F1': f1_score(y_test_heart, y_pred_t, zero_division=0),\n",
    "        'Accuracy': accuracy_score(y_test_heart, y_pred_t)\n",
    "    })\n",
    "\n",
    "df_thresh = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_thresh['Threshold'], df_thresh['Precision'], 'b-o', label='Precision', markersize=4)\n",
    "plt.plot(df_thresh['Threshold'], df_thresh['Recall'], 'r-o', label='Recall', markersize=4)\n",
    "plt.plot(df_thresh['Threshold'], df_thresh['F1'], 'g-o', label='F1', markersize=4)\n",
    "plt.plot(df_thresh['Threshold'], df_thresh['Accuracy'], 'k--', label='Accuracy', markersize=4, alpha=0.5)\n",
    "plt.axvline(x=0.5, color='gray', linestyle=':', label='Default threshold')\n",
    "plt.xlabel('Decision Threshold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Metrics as a Function of Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 Multi-class Classification\n",
    "\n",
    "Two main approaches:\n",
    "- **One-vs-Rest (OvR):** $K$ binary models, each distinguishing one class from the rest\n",
    "- **Softmax Regression (Multinomial):** A single model that directly handles $K$ classes\n",
    "\n",
    "$$P(y=k | x) = \\frac{e^{\\theta_k^T x}}{\\sum_{j=1}^{K} e^{\\theta_j^T x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load Iris dataset\n",
    "df_iris = pd.read_csv('data/iris.csv')\n",
    "print(f'Iris dataset shape: {df_iris.shape}')\n",
    "print(f'\\nClass distribution:')\n",
    "print(df_iris['target'].value_counts().sort_index())\n",
    "\n",
    "target_names = ['setosa', 'versicolor', 'virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_iris = df_iris.drop('target', axis=1).values\n",
    "y_iris = df_iris['target'].astype(int).values\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=RANDOM_STATE, stratify=y_iris\n",
    ")\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_iris_s = scaler_iris.fit_transform(X_train_iris)\n",
    "X_test_iris_s = scaler_iris.transform(X_test_iris)\n",
    "\n",
    "# Compare OvR vs Softmax\n",
    "models_mc = {\n",
    "    'One-vs-Rest (OvR)': LogisticRegression(multi_class='ovr', max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'Softmax (Multinomial)': LogisticRegression(multi_class='multinomial', max_iter=1000, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "for name, model in models_mc.items():\n",
    "    model.fit(X_train_iris_s, y_train_iris)\n",
    "    y_pred = model.predict(X_test_iris_s)\n",
    "    acc = accuracy_score(y_test_iris, y_pred)\n",
    "    print(f'\\n{name}:')\n",
    "    print(f'  Accuracy: {acc:.4f}')\n",
    "    print(classification_report(y_test_iris, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Multi-class confusion matrix\n",
    "softmax_model = models_mc['Softmax (Multinomial)']\n",
    "y_pred_iris = softmax_model.predict(X_test_iris_s)\n",
    "\n",
    "cm_iris = confusion_matrix(y_test_iris, y_pred_iris)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_iris, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Multi-class Confusion Matrix (Iris - Softmax)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary Visualization in 2D (first 2 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Use only first 2 features for visualization\n",
    "X_iris_2d = X_iris[:, :2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, mc_type) in zip(axes, [('OvR', 'ovr'), ('Softmax', 'multinomial')]):\n",
    "    model = LogisticRegression(multi_class=mc_type, max_iter=1000, random_state=RANDOM_STATE)\n",
    "    model.fit(X_iris_2d, y_iris)\n",
    "\n",
    "    x_min, x_max = X_iris_2d[:, 0].min() - 0.5, X_iris_2d[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_iris_2d[:, 1].min() - 0.5, X_iris_2d[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='Set1')\n",
    "    for cls, marker, label in zip([0, 1, 2], ['o', 's', '^'], target_names):\n",
    "        ax.scatter(X_iris_2d[y_iris==cls, 0], X_iris_2d[y_iris==cls, 1],\n",
    "                   marker=marker, edgecolors='k', s=50, label=label)\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_title(f'{name} Decision Boundary')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.5 Imbalanced Datasets\n",
    "\n",
    "When classes have very different sizes, accuracy can be misleading!\n",
    "\n",
    "Solutions:\n",
    "- `class_weight='balanced'` (weights the minority class more heavily)\n",
    "- Sampling techniques (SMOTE, etc.)\n",
    "- Using appropriate metrics (F1, balanced accuracy, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create imbalanced dataset\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000, n_features=10, n_informative=5,\n",
    "    n_classes=2, weights=[0.9, 0.1],\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f'Class distribution: 0 -> {np.sum(y_imb==0)}, 1 -> {np.sum(y_imb==1)}')\n",
    "print(f'Ratio: {np.sum(y_imb==0)/len(y_imb):.1%} vs {np.sum(y_imb==1)/len(y_imb):.1%}')\n",
    "\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.3, random_state=RANDOM_STATE, stratify=y_imb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare: without vs with class_weight='balanced'\n",
    "models_imb = {\n",
    "    'Default (no weighting)': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'class_weight=\\'balanced\\'': LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE, max_iter=1000)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, (name, model) in zip(axes, models_imb.items()):\n",
    "    model.fit(X_train_imb, y_train_imb)\n",
    "    y_pred = model.predict(X_test_imb)\n",
    "\n",
    "    cm = confusion_matrix(y_test_imb, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "    acc = accuracy_score(y_test_imb, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test_imb, y_pred)\n",
    "    f1 = f1_score(y_test_imb, y_pred)\n",
    "    rec = recall_score(y_test_imb, y_pred)\n",
    "    ax.set_title(f'{name}\\nAcc={acc:.3f}  Bal.Acc={bal_acc:.3f}  F1={f1:.3f}  Recall={rec:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nNote: the default model achieves high accuracy but low recall on the minority class!')\n",
    "print('Balanced weighting improves recall, but accuracy may slightly decrease.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ROC comparison on imbalanced data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for name, model in models_imb.items():\n",
    "    y_prob = model.predict_proba(X_test_imb)[:, 1]\n",
    "    fpr_i, tpr_i, _ = roc_curve(y_test_imb, y_prob)\n",
    "    auc_i = auc(fpr_i, tpr_i)\n",
    "    ax.plot(fpr_i, tpr_i, linewidth=2, label=f'{name} (AUC={auc_i:.3f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Comparison - Imbalanced Data')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Exercises\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 In-class Exercises – Linear Regression\n",
    "\n",
    "### E1. Mini-batch Gradient Descent\n",
    "\n",
    "Implement the **mini-batch gradient descent** algorithm! Use the synthetic data generated in Section 1.1 (`X_b`, `y_simple`).\n",
    "\n",
    "**Steps:**\n",
    "1. Write a `mini_batch_gradient_descent(X, y, theta, learning_rate, n_epochs, batch_size)` function\n",
    "2. Run it with `batch_size = 16`\n",
    "3. Plot the cost function convergence and compare it with batch GD on the same graph\n",
    "4. Try different `batch_size` values (8, 16, 32, 64) and visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E1: Mini-batch GD ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E2. Linear Regression on Real Data\n",
    "\n",
    "Use the `data/diabetes.csv` dataset!\n",
    "\n",
    "**Steps:**\n",
    "1. Load the data and perform a brief EDA (descriptive statistics, correlation matrix heatmap)\n",
    "2. Select the target variable (e.g. `BMI` or `Glucose`) and the features\n",
    "3. Perform train-test split (80-20), then standardize the features\n",
    "4. Fit a `LinearRegression` model\n",
    "5. Evaluate: MSE, RMSE, R\\u00b2 metrics\n",
    "6. Create a residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E2: Diabetes regression ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3. Finding the Optimal Polynomial Degree\n",
    "\n",
    "Use the nonlinear data generated in Section 1.3 (`X_poly`, `y_poly`).\n",
    "\n",
    "**Steps:**\n",
    "1. Create a `Pipeline`: `PolynomialFeatures(degree=d)` + `LinearRegression()`\n",
    "2. Use 5-fold cross-validation (`cross_val_score`) to try degrees from 1 to 15\n",
    "3. Plot the mean CV error (neg_mean_squared_error) as a function of the degree\n",
    "4. Which degree is the best? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E3: Optimal polynomial degree ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 In-class Exercises – Logistic Regression\n",
    "\n",
    "### E4. Heart Disease Classification\n",
    "\n",
    "Use the `data/heart-disease.csv` dataset!\n",
    "\n",
    "**Steps:**\n",
    "1. Load the data and perform a brief EDA (class distribution, correlation matrix)\n",
    "2. Train-test split (80-20, stratified), standardization\n",
    "3. Fit a logistic regression model\n",
    "4. Plot: (a) confusion matrix heatmap, (b) ROC curve with AUC value\n",
    "5. Print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E4: Heart Disease classification ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E5. Threshold Tuning\n",
    "\n",
    "Use the heart disease model from Section 2.3 (`log_reg_heart`, `y_prob_heart`).\n",
    "\n",
    "**Steps:**\n",
    "1. Set the decision threshold to 0.3: `y_pred_03 = (y_prob_heart >= 0.3).astype(int)`\n",
    "2. Also set the decision threshold to 0.7\n",
    "3. For all three thresholds (0.3, 0.5, 0.7), compute: precision, recall, F1, accuracy\n",
    "4. Compare the results in a table (DataFrame)\n",
    "5. **Question:** In medical diagnostics, which threshold would you choose, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E5: Threshold tuning ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E6. Multi-class Classification – Iris\n",
    "\n",
    "Use the Iris dataset!\n",
    "\n",
    "**Steps:**\n",
    "1. Fit logistic regression with both OvR and Softmax strategies\n",
    "2. Plot a confusion matrix for each\n",
    "3. Compare the results (accuracy, macro F1)\n",
    "4. **Question:** Is there a significant difference between the two approaches on this data? When would the difference be larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- IN-CLASS EXERCISE E6: Multi-class classification ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Homework – Linear Regression\n",
    "\n",
    "### HW1. USA Housing – Full Regression Analysis\n",
    "\n",
    "Perform a **complete regression analysis** on the `USA_Housing.csv` data!\n",
    "\n",
    "**Requirements:**\n",
    "1. **EDA** (min. 3 visualizations): distributions, correlations, scatter plots\n",
    "2. **Preprocessing:** train-test split, feature scaling (try both StandardScaler and MinMaxScaler)\n",
    "3. **Modeling:** Linear Regression, Ridge, Lasso, Elastic Net (min. 3 alpha values for each)\n",
    "4. **Comparison:** Create a summary table with MSE and R\\u00b2 values for all models\n",
    "5. **Learning curves:** Plot the learning curve for the best model\n",
    "6. **Conclusion:** Which model performs best and why? Is there overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- HOMEWORK HW1: USA Housing regression analysis ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2. Normal Equation vs. Gradient Descent – Comparison\n",
    "\n",
    "Compare the efficiency of the normal equation and gradient descent on data of different sizes!\n",
    "\n",
    "**Requirements:**\n",
    "1. Generate synthetic data of various sizes: $m \\in \\{100, 500, 1000, 5000, 10000, 50000\\}$ and $n \\in \\{5, 10, 50\\}$ features\n",
    "2. Implement the normal equation and batch gradient descent from scratch\n",
    "3. Measure the runtime for both methods (use the `time` module)\n",
    "4. Plot the runtimes as a function of $m$ and $n$ (2 plots)\n",
    "5. **Question:** When should you use the normal equation, and when GD? (Theoretically: NE \\u2208 $O(n^3)$, GD \\u2208 $O(m \\cdot n \\cdot k)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- HOMEWORK HW2: Normal equation vs. GD ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.4 Homework – Logistic Regression\n",
    "\n",
    "### HW3. Titanic – Full Classification Analysis\n",
    "\n",
    "Perform a **complete classification analysis** on `data/titanic_train.csv`!\n",
    "\n",
    "**Requirements:**\n",
    "1. **EDA:** Examine the data (missing values, distributions, relationships with survival)\n",
    "2. **Feature engineering:**\n",
    "   - Handle missing values (`Age` -> median, `Embarked` -> mode, `Cabin` -> drop)\n",
    "   - Encode categorical variables (`Sex`, `Embarked`)\n",
    "   - Optional: create new features (e.g. `FamilySize = SibSp + Parch + 1`)\n",
    "3. **Modeling:** Logistic regression (try: C=0.01, 0.1, 1, 10)\n",
    "4. **Evaluation:** Confusion matrix, classification report, ROC curve\n",
    "5. **Regularization:** Compare L1 and L2 regularization (penalty='l1' vs 'l2')\n",
    "6. **Conclusion:** Which features are most important for predicting survival? (analyze coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- HOMEWORK HW3: Titanic classification ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4. Imbalanced Data – Metrics Analysis\n",
    "\n",
    "Examine how different metrics behave on imbalanced data!\n",
    "\n",
    "**Requirements:**\n",
    "1. Generate imbalanced data using `make_classification` with different ratios:\n",
    "   - Mild: 70%-30%\n",
    "   - Moderate: 90%-10%\n",
    "   - Severe: 99%-1%\n",
    "2. For each ratio, fit logistic regression:\n",
    "   - (a) `class_weight=None` (default)\n",
    "   - (b) `class_weight='balanced'`\n",
    "3. For each combination, compute: accuracy, balanced_accuracy, precision, recall, F1, AUC\n",
    "4. Create a summary table (DataFrame) and visualize the results\n",
    "5. **Questions:**\n",
    "   - Which metric is most informative on imbalanced data?\n",
    "   - Up to what imbalance ratio is accuracy still sufficient?\n",
    "   - When should you use the `class_weight='balanced'` setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- HOMEWORK HW4: Imbalanced metrics analysis ---\n",
    "# Write your solution here!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
